name: Benchmark GTSFM on select datasets
on: [pull_request]
jobs:
  benchmark:
    name: Run GTSFM on the select dataset using SIFT front-end
    runs-on: ubuntu-latest
    defaults:
      run:
        shell: bash -l {0}

    env:
      PYTHON_VERSION: 3.8

    steps:
      - uses: actions/checkout@v2
      - name: Cache conda env
        uses: actions/cache@v2
        env:
          # Increase this value to reset cache if environment_linux.yml has not changed
          CACHE_NUMBER: 0
        with:
          path: ~/conda_pkgs_dir
          key:
            ${{ runner.os }}-conda-${{ env.CACHE_NUMBER }}-${{hashFiles('environment_linux.yml') }}
      - uses: conda-incubator/setup-miniconda@v2
        with:
          miniconda-version: "latest"
          activate-environment: gtsfm-v1
          environment-file: environment_linux.yml
          python-version: 3.8
          use-only-tar-bz2: true # IMPORTANT: This needs to be set for caching to work properly!
      - name: Environment setup
        run: |
          bash .github/scripts/setup.sh
          conda info
      - name: Download Skydio-crane-8 dataset
        # large files from google drive first have a prompt about virus scan being inactive. Need 2 WGET commands.
        run: |
          export gdrive_fileid='1mmM1p_NpL7-pnf3iHWeWVKpsm1pcBoD5'
          export gdrive_url='https://docs.google.com/uc?export=download&id='$gdrive_fileid 
          wget --save-cookies cookies.txt $gdrive_url -O- \
            | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\1/p' > confirm.txt
          wget --load-cookies cookies.txt -O skydio-8.zip \
            $gdrive_url'&confirm='$(<confirm.txt)
      - name: Download Skydio-crane-32 dataset
        # large files from google drive first have a prompt about virus scan being inactive. Need 2 WGET commands.
        run: |
          export gdrive_fileid='1BQ6jp0DD3D9yhTnrDoEddzlMYT0RRH68'
          export gdrive_url='https://docs.google.com/uc?export=download&id='$gdrive_fileid 
          wget --save-cookies cookies.txt $gdrive_url -O- \
            | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\1/p' > confirm.txt
          wget --load-cookies cookies.txt -O skydio-32.zip \
            $gdrive_url'&confirm='$(<confirm.txt)
      - name: Decompress Skydio-crane-8 dataset
        uses: TonyBogdanov/zip@1.0
        with:
          args: unzip -qq skydio-8.zip 
      - name: Decompress Skydio-crane-32 dataset
        uses: TonyBogdanov/zip@1.0
        with:
          args: unzip -qq skydio-32.zip -d skydio-32
      - name: Execute door dataset
        run: |
          python gtsfm/runner/run_scene_optimizer.py --config_name sift_front_end.yaml
      - name: Archive door dataset metrics
        uses: actions/upload-artifact@v2
        with:
          name: door-raw-metrics
          path: |
            result_metrics
      - name: Execute skydio-crane-8 dataset
        run: |
          python gtsfm/runner/run_scene_optimizer_colmaploader.py \
            --images_dir skydio_crane_mast_8imgs_with_exif/images \
            --colmap_files_dirpath skydio_crane_mast_8imgs_with_exif/crane_mast_8imgs_colmap_output \
            --max_frame_lookahead 8 \
            --config_name sift_front_end.yaml
      - name: Archive skydio-crane-8 metrics
        uses: actions/upload-artifact@v2
        with:
          name: skydio-crane-8-raw-metrics
          path: |
            result_metrics
      - name: Execute skydio-crane-32 dataset
        run: |
          python gtsfm/runner/run_scene_optimizer_colmaploader.py \
            --images_dir skydio-32/images \
            --colmap_files_dirpath skydio-32/colmap_crane_mast_32imgs \
            --max_frame_lookahead 32 \
            --config_name sift_front_end.yaml
      - name: Archive skydio-crane-32 metrics
        uses: actions/upload-artifact@v2
        with:
          name: skydio-crane-32-raw-metrics
          path: |
            result_metrics
