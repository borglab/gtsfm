{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c3aafcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import gtsam\n",
    "\n",
    "import gtsfm.utils.io as io_utils\n",
    "import gtsfm.utils.logger as logger_utils\n",
    "from gtsfm.utils import align, transform\n",
    "\n",
    "import visu3d as v3d\n",
    "\n",
    "logger = logger_utils.get_logger()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad16454",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_ROOT = Path.cwd().parent.resolve()\n",
    "GT_MODEL_DIR = REPO_ROOT / \"tests/data/set1_lund_door/colmap_ground_truth\"\n",
    "# GT_MODEL_DIR = REPO_ROOT / \"benchmarks/gerrard-hall/sparse\"\n",
    "ANY_SPLAT_MODEL_DIR = REPO_ROOT / \"anysplat_door_results_with_BA/results/C_1/anysplat\"\n",
    "MVO_SPLAT_MODEL_DIR = REPO_ROOT / \"mvo_door_results/results/ba_output\"\n",
    "\n",
    "\n",
    "print(f\"Using repo root: {REPO_ROOT}\")\n",
    "print(f\"Ground truth COLMAP dir: {GT_MODEL_DIR}\")\n",
    "print(f\"AnySplat COLMAP dir:     {ANY_SPLAT_MODEL_DIR}\")\n",
    "print(f\"MVO COLMAP dir:     {MVO_SPLAT_MODEL_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4418840",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class PoseRecord:\n",
    "    name: str\n",
    "    center: np.ndarray\n",
    "    rotation: np.ndarray\n",
    "    direction: np.ndarray\n",
    "\n",
    "\n",
    "def _normalize(vec: np.ndarray) -> np.ndarray:\n",
    "    norm = np.linalg.norm(vec)\n",
    "    if norm < 1e-9:\n",
    "        return vec\n",
    "    return vec / norm\n",
    "\n",
    "def calibration_to_spec(calib: gtsam.Cal3, hw: tuple[int, int]) -> v3d.CameraSpec:\n",
    "    h, w = hw\n",
    "    if isinstance(calib, gtsam.Cal3_S2):\n",
    "        fx, fy = calib.fx(), calib.fy()\n",
    "        cx, cy = calib.px(), calib.py()\n",
    "    elif isinstance(calib, (gtsam.Cal3Bundler, gtsam.Cal3Unified)):  # fx == fy\n",
    "        fx = fy = calib.fx()\n",
    "        cx, cy = calib.px(), calib.py()\n",
    "    elif isinstance(calib, gtsam.Cal3DS2):\n",
    "        fx, fy = calib.fx(), calib.fy()\n",
    "        cx, cy = calib.px(), calib.py()\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported calibration type: {type(calib)}\")\n",
    "\n",
    "    K = np.array([[fx, 0, cx],\n",
    "                  [0, fy, cy],\n",
    "                  [0,  0,  1]], dtype=np.float32)\n",
    "    return v3d.PinholeCamera(K=K, resolution=(h, w))\n",
    "\n",
    "def load_poses(colmap_dirpath):\n",
    "    \"\"\"Returns mapping from image filename to associated camera pose.\"\"\"\n",
    "    wTi_list, img_fnames, calibrations, _, _, img_dims = io_utils.read_scene_data_from_colmap_format(colmap_dirpath)\n",
    "    pose_map, spec_map = {}, {}\n",
    "    for name, pose, calib, hw in zip(img_fnames, wTi_list, calibrations, img_dims):\n",
    "        key = Path(name).name\n",
    "        pose_map[key] = pose\n",
    "        spec_map[key] = calibration_to_spec(calib, hw)\n",
    "    logger.info(\"Loaded %d poses from %s\", len(pose_map), colmap_dirpath)\n",
    "    return pose_map, spec_map\n",
    "    \n",
    "\n",
    "def pose_records_from_map(pose_map: Dict[str, gtsam.Pose3]) -> List[PoseRecord]:\n",
    "    records: List[PoseRecord] = []\n",
    "    forward_axis = np.array([0.0, 0.0, 1.0], dtype=np.float64)\n",
    "    for name in sorted(pose_map.keys()):\n",
    "        pose = pose_map[name]\n",
    "        t = pose.translation()\n",
    "        center = np.array([t[0], t[1], t[2]], dtype=np.float64)\n",
    "        R = pose.rotation().matrix()\n",
    "        direction = _normalize(R @ forward_axis)\n",
    "        records.append(PoseRecord(name=name, center=center, rotation=R, direction=direction))\n",
    "    return records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6b2a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_pose_maps_to_reference(\n",
    "    reference_pose_map: Dict[str, gtsam.Pose3], estimate_pose_map: Dict[str, gtsam.Pose3]\n",
    "):\n",
    "    common_names = sorted(set(reference_pose_map) & set(estimate_pose_map))\n",
    "    if len(common_names) < 2:\n",
    "        raise ValueError(\"Need at least 2 overlapping cameras to estimate Sim(3) alignment\")\n",
    "    ref_list = [reference_pose_map[name] for name in common_names]\n",
    "    est_list = [estimate_pose_map[name] for name in common_names]\n",
    "    aSb = align.sim3_from_Pose3s(ref_list, est_list)\n",
    "    names, poses = zip(*estimate_pose_map.items()) if estimate_pose_map else ([], [])\n",
    "    aligned_list = transform.Pose3s_with_sim3(aSb, list(poses)) if poses else []\n",
    "    aligned_map = dict(zip(names, aligned_list))\n",
    "    summary = {\n",
    "        \"scale\": float(aSb.scale()),\n",
    "        \"translation\": np.array(aSb.translation()),\n",
    "        \"rotation\": aSb.rotation().matrix(),\n",
    "        \"num_common\": len(common_names),\n",
    "    }\n",
    "    return aligned_map, summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4528500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclass_array as dca\n",
    "\n",
    "def make_camera_batch(pose_map, spec_map) -> v3d.Camera:\n",
    "    cams = []\n",
    "    for name in sorted(pose_map):\n",
    "        pose = pose_map[name]\n",
    "        spec = spec_map[name]\n",
    "\n",
    "        t = pose.translation()\n",
    "        world_from_cam = v3d.Transform(\n",
    "            R=pose.rotation().matrix(),\n",
    "            t=np.array([t[0], t[1], t[2]], dtype=np.float32),\n",
    "        )\n",
    "        cams.append(v3d.Camera(spec=spec, world_from_cam=world_from_cam))\n",
    "    return dca.stack(cams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2147675c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_pose_map, gt_spec_map = load_poses(str(GT_MODEL_DIR))\n",
    "any_pose_map, any_spec_map = load_poses(str(ANY_SPLAT_MODEL_DIR))\n",
    "mvo_pose_map, mvo_spec_map = load_poses(str(MVO_SPLAT_MODEL_DIR))\n",
    "\n",
    "\n",
    "aligned_any_pose_map, sim3_summary = align_pose_maps_to_reference(gt_pose_map, any_pose_map)\n",
    "aligned_mvo_pose_map, sim3_summary_mvo = align_pose_maps_to_reference(gt_pose_map, mvo_pose_map)\n",
    "\n",
    "\n",
    "gt_records = pose_records_from_map(gt_pose_map)\n",
    "aligned_any_records = pose_records_from_map(aligned_any_pose_map)\n",
    "aligned_mvo_records = pose_records_from_map(aligned_mvo_pose_map)\n",
    "\n",
    "\n",
    "print(f\"Loaded {len(gt_records)} GT poses and {len(aligned_any_records)} AnySplat poses.\")\n",
    "print(f\"Alignment used {sim3_summary['num_common']} shared image names between AnySplat and gt.\")\n",
    "print(f\"Estimated scale: {sim3_summary['scale']:.4f} for AnySplat\")\n",
    "\n",
    "print(f\"Loaded {len(gt_records)} GT poses and {len(aligned_mvo_records)} mvo poses.\")\n",
    "print(f\"Alignment used {sim3_summary_mvo['num_common']} shared image names between mvo and gt.\")\n",
    "print(f\"Estimated scale: {sim3_summary_mvo['scale']:.4f} for mvo\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944d0d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_cams = make_camera_batch(gt_pose_map, gt_spec_map)\n",
    "any_cams = make_camera_batch(aligned_any_pose_map, any_spec_map)\n",
    "mvo_cams = make_camera_batch(aligned_mvo_pose_map, mvo_spec_map)\n",
    "\n",
    "\n",
    "fig = v3d.make_fig(\n",
    "    gt_cams.replace_fig_config(name=\"Ground truth\", scale=0.3),\n",
    "    any_cams.replace_fig_config(name=\"AnySplat (aligned)\", scale=0.3),\n",
    "    # mvo_cams.replace_fig_config(name=\"MVO (aligned)\", scale=0.3),\n",
    "    show_zero=True,\n",
    ")\n",
    "fig.update_layout(width=800, height=600)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339521e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rays_from_records(records: List[PoseRecord]) -> v3d.Ray:\n",
    "#     centers = np.stack([rec.center for rec in records], axis=0).astype(np.float32)\n",
    "#     directions = np.stack([rec.direction for rec in records], axis=0).astype(np.float32)\n",
    "#     return v3d.Ray(pos=centers, dir=directions).normalize()\n",
    "\n",
    "\n",
    "# gt_rays = rays_from_records(gt_records)\n",
    "# any_aligned_rays = rays_from_records(aligned_any_records)\n",
    "# mvo_aligned_rays = rays_from_records(aligned_mvo_records)\n",
    "\n",
    "# gt_rays.pos.shape, any_aligned_rays.pos.shape, mvo_aligned_rays.pos.shape\n",
    "# gt_rays_named = gt_rays.replace(\n",
    "#     fig_config=gt_rays.fig_config.replace(name=\"Ground truth\")\n",
    "# )\n",
    "# any_rays_named = any_aligned_rays.replace(\n",
    "#     fig_config=any_aligned_rays.fig_config.replace(name=\"AnySplat (aligned)\")\n",
    "# )\n",
    "# mvo_rays_named = mvo_aligned_rays.replace(\n",
    "#     fig_config=mvo_aligned_rays.fig_config.replace(name=\"MVO (aligned)\")\n",
    "# )\n",
    "\n",
    "# fig = v3d.make_fig(\n",
    "#     gt_rays_named,\n",
    "#     # any_rays_named,\n",
    "#     mvo_rays_named,\n",
    "#     show_zero=True,\n",
    "#     cam_scale=0.5,\n",
    "# )\n",
    "# fig.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58106c06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ee889e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gtsfm-v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
