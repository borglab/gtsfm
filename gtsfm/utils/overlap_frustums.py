""" Scripts to calculate the overlap area of frustums and transform foreground object in the unit cube

Author: Ren Liu
"""

import argparse
import json
import os
from typing import Dict, List, Tuple

import matplotlib.pyplot as plt
import numpy as np
from sklearn.cluster import DBSCAN
from tqdm import tqdm

# minimum number of voxels in the overlap of frustums
MIN_VOXELS_OVERLAP_FRUSTUM = 1000


def parse_args() -> argparse.Namespace:
    """parse arguments from user input"""

    parser = argparse.ArgumentParser()
    parser.add_argument("-t", "--transform", help="path/to/transforms.json generated by colmap2nerf.py")
    parser.add_argument("-r", "--resolution", type=int, default=128)
    parser.add_argument("-o", "--output", help="output path", default=".")
    return parser.parse_args()


def gen_cube_voxels(start: float, end: float, resolution: int) -> np.ndarray:
    """Generate grid voxels for a cube of certain resolutions.
                         _____ (end, end, end)
                        /____/|
                        |    || resolution
                        |____|/
    (start, start, start)
    Args:
        start: location of bottom-left-front vertex of the cube
        end: location of top-right-rear vertex of the cube
        resolution: number of voxels per edge
    Return:
        coordinates of bottom-left-front vertices of generated voxels, in shape of (resolution**3, 3)
    """
    edge_space = np.linspace(start, end, resolution)

    x_grid, y_grid, z_grid = np.meshgrid(edge_space, edge_space, edge_space, indexing="xy")
    x_grid = x_grid.reshape([-1, 1])
    y_grid = y_grid.reshape([-1, 1])
    z_grid = z_grid.reshape([-1, 1])

    return np.concatenate([x_grid, y_grid, z_grid], axis=-1)


def draw_overlap_frustum(overlap: np.ndarray, cameras: np.ndarray, out_path: str, draw_unit_cube: bool = True) -> None:
    """draw calculated overlap area of frustums and save to an image
    Args:
        overlap: grid voxel coordinates, in shape of (N, 3)
        cameras: camera coordinates, in shape of (M, 3)
        out_path: output image path
        draw_unit_cube: whether to draw the unit cube, default as True
    """
    fig = plt.figure(figsize=(8, 6))
    ax = fig.add_subplot(111, projection="3d")
    # draw camera centers
    ax.scatter(cameras[:, 0], cameras[:, 1], cameras[:, 2], c="b", marker="x", label="cameras")
    # draw voxels
    ax.scatter(overlap[:, 0], overlap[:, 1], overlap[:, 2], c="g", marker="o", label="overlap of frustums")

    # if draw the unit cube on the output image
    if draw_unit_cube:
        unit_cube = np.array([[0, 0, 0], [0, 0, 1], [0, 1, 0], [1, 0, 0], [1, 1, 0], [0, 1, 1], [1, 0, 1], [1, 1, 1]])
        ax.scatter(unit_cube[:, 0], unit_cube[:, 1], unit_cube[:, 2], c="r", marker="^", label="Unit Cube")

    ax.set_xlabel("X")
    ax.set_ylabel("Y")
    ax.set_zlabel("Z")

    ax.legend()
    ax.grid(True)

    plt.savefig(out_path)


def parse_nerf_transforms(
    transforms_data: Dict,
) -> Tuple[int, int, int, np.ndarray, np.ndarray, List[np.ndarray]]:
    """parse NeRF-style transforms.json file

    Args:
        transforms_data: loaded transforms.json file as python dictionary

    Returns:
        image_width: width in pixel of images
        image_height: height in pixel of images
        cube_size: original aabb box scale, should be power of 2
        camera_centers: centers of all cameras in world frame, in shape of (N, 3)
        K: the shared camera intrinsic matrix, in shape of (3, 3)
        iTw_list: list of camera transform matrices |R t|, in shape of (4, 4)
                                              |0 1|
    """

    # load camera intrinsics
    K = np.zeros([3, 3])
    K[0][0] = transforms_data["fl_x"]
    K[0][2] = transforms_data["cx"]
    K[1][1] = transforms_data["fl_y"]
    K[1][2] = transforms_data["cy"]
    K[2][2] = 1

    # load transform matrices |R t|
    #                         |0 1|
    iTw_list = [np.linalg.inv(np.array(frame["transform_matrix"])) for frame in transforms_data["frames"]]

    # load original aabb box scale, should be power of 2
    cube_size = transforms_data["aabb_scale"]

    # load image size
    image_width, image_height = transforms_data["w"], transforms_data["h"]

    camera_centers = []
    for iTw in iTw_list:
        t = iTw[:-1, -1]
        R = iTw[:-1, :-1]

        # compute camera i coordinates in world frame, and add to camera list
        camera_centers.append(-R.T @ t)

    camera_centers = np.array(camera_centers)

    return image_width, image_height, cube_size, camera_centers, K, iTw_list


def calculate_overlap_frustums(
    cube_size: int, cube_resolution: int, w: int, h: int, K: np.ndarray, iTw_list: List[np.ndarray]
) -> np.ndarray:
    """calculate the overlap area of frustums

    Args:
        cube_size: original aabb box scale, should be power of 2
        cube_resolution: sample resolution for the original aabb box
        w: width in pixel of images
        h: height in pixel of images
        K: the shared camera intrinsic matrix, in shape of (3, 3)
        iTw_list: list of camera transform matrices |R t|, in shape of (4, 4)
                                              |0 1|

    Returns:
        filtered grid voxels lying in the overlap area of frustums, in shape of (M, 3),
            MIN_VOXELS_OVERLAP_FRUSTUM <= M <= cube_resolution ** 3
    """
    cube_grid = gen_cube_voxels(-cube_size / 2, cube_size / 2, cube_resolution)
    # transform to homogeneous coordinates, in shape of (resolution ** 3, 4)
    cube_grid_homo = np.concatenate([cube_grid, np.ones([cube_resolution**3, 1])], axis=-1)

    # record the number of frustums each voxels is in
    num_frustum_voxel = np.zeros([cube_resolution**3], dtype=np.float32)

    # generalize intrinsic camera from 3x3 to 3x4
    K = K @ np.eye(3, 4)

    for iTw in tqdm(iTw_list):

        # compute corresponding pixel location (u, v) in camera i
        uv_homo = (K @ iTw @ cube_grid_homo.T).T
        uv = uv_homo[:, :-1] / uv_homo[:, -1:]
        u, v = uv[:, 0], uv[:, 1]

        # check whether the grid voxels can be seen from camera i
        frustum_i = v >= 0
        frustum_i = np.logical_and(frustum_i, v < h)
        frustum_i = np.logical_and(frustum_i, 0 <= u)
        frustum_i = np.logical_and(frustum_i, u < w)

        num_frustum_voxel = num_frustum_voxel + frustum_i.astype(np.float32)

    # decide the minimum percentile of the number of frustums for each voxel to be considered as the overlap of frustums
    min_overlap_percentile = min(99, 100 * (1 - MIN_VOXELS_OVERLAP_FRUSTUM / cube_resolution**3))
    is_overlap_frustums = num_frustum_voxel >= np.percentile(num_frustum_voxel, min_overlap_percentile)
    overlap_grid = cube_grid[is_overlap_frustums]

    # use DBSCAN to cluster the overlap area and filter out the noisy samples
    clustering = DBSCAN(eps=np.sqrt(3) * cube_size / cube_resolution, min_samples=2).fit(overlap_grid)
    overlap_grid = overlap_grid[clustering.labels_ != -1]

    return overlap_grid


def transform_to_unit_cube(overlap_grid: np.ndarray) -> Tuple[np.ndarray, float, np.ndarray]:
    """transform the overlap grid into the unit cube

    Args:
        overlap_grid: filtered grid voxels lying in the overlap area of frustums, in shape of (M, 3),
            MIN_VOXELS_OVERLAP_FRUSTUM <= M <= cube_resolution ** 3

    Returns:
        transformed_grid: transformed grid voxels lying in the unit cube, in shape of (M, 3),
            MIN_VOXELS_OVERLAP_FRUSTUM <= M <= cube_resolution ** 3
        scale: calculated scale
        offset: calculated offset vector, in shape of (3, )
    """
    # The instant-ngp will make transformation by first performing scale then adding offset.
    #   Ref: https://github.com/NVlabs/instant-ngp/blob/b97faed27aeacb6bfd91c6e7171d7e952e917e67/src/nerf_loader.cu#L424
    #   1. scale the overlap grid to let all voxels fit with the unit cube
    max_overlap_grid_dim = max(overlap_grid.max(axis=0) - overlap_grid.min(axis=0))
    scale = 1 / max_overlap_grid_dim

    transformed_grid = overlap_grid * scale

    #   2. calculate the offset according to the scaled grid
    grid_center = transformed_grid.mean(axis=0)
    unit_cube_center = np.array([0.5, 0.5, 0.5])
    offset = unit_cube_center - grid_center

    transformed_grid += offset

    return transformed_grid, scale, offset


if __name__ == "__main__":

    args = parse_args()

    # check and make output directory
    if not os.path.exists(args.output):
        os.makedirs(args.output)

    # load NeRF transformation file, usually named as transforms.json
    with open(args.transform, "r") as f:
        transforms_data = json.load(f)

    # parse the NeRF-style transforms.json
    w, h, cube_size, camera_centers, K, iTw_list = parse_nerf_transforms(transforms_data)

    # compute the overlap area of the frustums
    overlap_grid = calculate_overlap_frustums(cube_size, args.resolution, w, h, K, iTw_list)

    # draw the overlap area before transformation
    draw_overlap_frustum(overlap_grid, camera_centers, out_path=os.path.join(args.output, "beforeTransform.png"))

    # transform the overlap area into the unit cube
    transformed_grid, scale, offset = transform_to_unit_cube(overlap_grid)
    print(f"Result:  scale={scale:.3f}, offset={offset.round(3)}")

    # transform the camera centers
    transformed_camera_centers = camera_centers * scale + offset

    # draw the overlap area after transformation
    draw_overlap_frustum(
        transformed_grid, transformed_camera_centers, out_path=os.path.join(args.output, "afterTransform.png")
    )

    # write the computed scale and offset back to the transforms data
    transforms_data["scale"] = scale
    transforms_data["offset"] = offset.tolist()

    with open(os.path.join(args.output, "transforms-out.json"), "w+") as f:
        json.dump(transforms_data, f, indent=4)
