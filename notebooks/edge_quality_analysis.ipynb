{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# Edge Quality Analysis\n",
    "Post-hoc analysis of visibility graph edge quality after a GTSFM pipeline run.\n",
    "\n",
    "Loads `edge_quality_report.json` and `cluster_tree.pkl` from a completed run,\n",
    "then visualizes bad edges, cluster structure, and the effect of pruning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": "from pathlib import Path\n\n# === CONFIGURE THESE ===\nOUTPUT_ROOT = Path(\"../results\")  # --output_root used for the pipeline run\nPRUNED_OUTPUT_ROOT = Path(\"../results_pruned\")  # --output_root for pruned run\nIMAGES_DIR = Path(\"../benchmarks/gerrard-hall/images\")  # directory with source images\n\n# Derived paths\nEDGE_QUALITY_JSON = OUTPUT_ROOT / \"results\" / \"edge_quality_report.json\"\nCLUSTER_TREE_PKL = OUTPUT_ROOT / \"results\" / \"cluster_tree.pkl\"\nPRUNED_EDGE_QUALITY_JSON = PRUNED_OUTPUT_ROOT / \"results\" / \"edge_quality_report.json\"\nPRUNED_CLUSTER_TREE_PKL = PRUNED_OUTPUT_ROOT / \"results\" / \"cluster_tree.pkl\""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Load edge quality report\n",
    "with open(EDGE_QUALITY_JSON) as f:\n",
    "    report = json.load(f)\n",
    "\n",
    "# Load cluster tree\n",
    "with open(CLUSTER_TREE_PKL, \"rb\") as f:\n",
    "    cluster_tree = pickle.load(f)\n",
    "\n",
    "# Extract image filenames (added in our export update)\n",
    "image_filenames = report.get(\"image_filenames\", [])\n",
    "\n",
    "# Parse edge quality into dict of (i,j) -> stats\n",
    "edge_quality = {}\n",
    "for edge_str, stats in report[\"edge_quality\"].items():\n",
    "    i, j = map(int, edge_str.strip(\"()\").split(\",\"))\n",
    "    edge_quality[(i, j)] = stats\n",
    "\n",
    "bad_edges = set()\n",
    "for s in report[\"bad_edges\"]:\n",
    "    i, j = map(int, s.strip(\"()\").split(\",\"))\n",
    "    bad_edges.add((i, j))\n",
    "\n",
    "metadata = report[\"metadata\"]\n",
    "print(f\"Total edges: {metadata['total_edges']}\")\n",
    "print(f\"Bad edges:   {metadata['bad_edge_count']}\")\n",
    "print(f\"Edges with no tracks: {metadata['edges_with_no_tracks']}\")\n",
    "print(f\"Image filenames available: {len(image_filenames) > 0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stats-header",
   "metadata": {},
   "source": [
    "## 1. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary-stats",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "track_counts = []\n",
    "for stats in edge_quality.values():\n",
    "    val = stats[\"mean_reproj_error_px\"]\n",
    "    if val != \"inf\":\n",
    "        errors.append(val)\n",
    "    track_counts.append(stats[\"num_tracks\"])\n",
    "\n",
    "errors = np.array(errors)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram of mean reprojection errors\n",
    "ax = axes[0]\n",
    "ax.hist(errors, bins=50, edgecolor=\"black\", alpha=0.7)\n",
    "ax.axvline(5.0, color=\"red\", linestyle=\"--\", label=\"Bad threshold (5px)\")\n",
    "ax.set_xlabel(\"Mean Reprojection Error (px)\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_title(\"Distribution of Edge Reprojection Errors\")\n",
    "ax.legend()\n",
    "\n",
    "# Histogram of track counts\n",
    "ax = axes[1]\n",
    "ax.hist(track_counts, bins=50, edgecolor=\"black\", alpha=0.7, color=\"steelblue\")\n",
    "ax.set_xlabel(\"Number of Supporting Tracks\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_title(\"Distribution of Track Counts per Edge\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean reproj error:  {np.mean(errors):.2f} px\")\n",
    "print(f\"Median reproj error: {np.median(errors):.2f} px\")\n",
    "print(f\"Max reproj error:   {np.max(errors):.2f} px\")\n",
    "print(f\"Edges > 5px: {np.sum(errors > 5.0)} / {len(errors)}\")\n",
    "print(f\"Edges > 3px: {np.sum(errors > 3.0)} / {len(errors)}\")\n",
    "print(f\"Edges > 1px: {np.sum(errors > 1.0)} / {len(errors)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad-edges-header",
   "metadata": {},
   "source": [
    "## 2. Bad Edge Image Pairs\n",
    "Showing the actual image pairs for the worst edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad-edge-images",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fname(idx):\n",
    "    \"\"\"Get image filename from index.\"\"\"\n",
    "    if idx < len(image_filenames):\n",
    "        return image_filenames[idx]\n",
    "    return f\"image_{idx:04d}.jpg\"\n",
    "\n",
    "\n",
    "def load_img(img_dir, fname):\n",
    "    \"\"\"Load image, trying common extensions if exact match fails.\"\"\"\n",
    "    path = img_dir / fname\n",
    "    if path.exists():\n",
    "        return np.array(Image.open(path))\n",
    "    for ext in [\".jpg\", \".jpeg\", \".png\", \".JPG\", \".PNG\"]:\n",
    "        candidate = img_dir / (Path(fname).stem + ext)\n",
    "        if candidate.exists():\n",
    "            return np.array(Image.open(candidate))\n",
    "    print(f\"  WARNING: Could not find {fname} in {img_dir}\")\n",
    "    return np.zeros((100, 100, 3), dtype=np.uint8)\n",
    "\n",
    "\n",
    "# Sort bad edges by error (worst first)\n",
    "bad_edge_list = sorted(\n",
    "    bad_edges,\n",
    "    key=lambda e: edge_quality[e][\"mean_reproj_error_px\"]\n",
    "    if edge_quality[e][\"mean_reproj_error_px\"] != \"inf\"\n",
    "    else float(\"inf\"),\n",
    "    reverse=True,\n",
    ")\n",
    "\n",
    "n_show = min(len(bad_edge_list), 10)\n",
    "\n",
    "if n_show > 0:\n",
    "    fig, axes = plt.subplots(n_show, 2, figsize=(12, 4 * n_show))\n",
    "    if n_show == 1:\n",
    "        axes = axes[np.newaxis, :]\n",
    "\n",
    "    for row, (i, j) in enumerate(bad_edge_list[:n_show]):\n",
    "        stats = edge_quality[(i, j)]\n",
    "        fname_i, fname_j = get_fname(i), get_fname(j)\n",
    "\n",
    "        axes[row, 0].imshow(load_img(IMAGES_DIR, fname_i))\n",
    "        axes[row, 0].set_title(f\"[{i}] {fname_i}\", fontsize=10)\n",
    "        axes[row, 0].axis(\"off\")\n",
    "\n",
    "        axes[row, 1].imshow(load_img(IMAGES_DIR, fname_j))\n",
    "        axes[row, 1].set_title(f\"[{j}] {fname_j}\", fontsize=10)\n",
    "        axes[row, 1].axis(\"off\")\n",
    "\n",
    "        err = stats[\"mean_reproj_error_px\"]\n",
    "        err_str = f\"{err:.1f}\" if err != \"inf\" else \"inf\"\n",
    "        axes[row, 0].set_ylabel(\n",
    "            f\"({i},{j}) err={err_str}px tracks={stats['num_tracks']}\",\n",
    "            fontsize=10, color=\"red\", rotation=0, labelpad=120, va=\"center\",\n",
    "        )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No bad edges found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graph-viz-header",
   "metadata": {},
   "source": [
    "## 3. Graph Visualization\n",
    "Interactive Plotly plots showing the visibility graph, clusters, and bad edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plotly-utils",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph visualization utilities (from partitioning.ipynb)\n",
    "import plotly.graph_objects as go\n",
    "from collections import deque\n",
    "from typing import Any, Dict, List, Set, Tuple\n",
    "\n",
    "\n",
    "def get_edge_coordinates(xy, edges):\n",
    "    \"\"\"Prepare edge coordinates for a Plotly Scatter trace.\"\"\"\n",
    "    if edges.size == 0:\n",
    "        return np.array([]), np.array([])\n",
    "    xe = np.empty(3 * len(edges))\n",
    "    ye = np.empty(3 * len(edges))\n",
    "    xe[0::3] = xy[edges[:, 0], 0]\n",
    "    ye[0::3] = xy[edges[:, 0], 1]\n",
    "    xe[1::3] = xy[edges[:, 1], 0]\n",
    "    ye[1::3] = xy[edges[:, 1], 1]\n",
    "    xe[2::3] = np.nan\n",
    "    ye[2::3] = np.nan\n",
    "    return xe, ye\n",
    "\n",
    "\n",
    "def create_base_figure_with_background(xy, edges_arr):\n",
    "    \"\"\"Creates a Plotly figure with all nodes and edges as a faint background.\"\"\"\n",
    "    fig = go.Figure()\n",
    "    xe_bg, ye_bg = get_edge_coordinates(xy, edges_arr)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=xe_bg, y=ye_bg, mode=\"lines\",\n",
    "        line=dict(width=1, color=\"lightgray\"),\n",
    "        opacity=0.2, hoverinfo=\"none\", showlegend=False,\n",
    "    ))\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=xy[:, 0], y=xy[:, 1], mode=\"markers\",\n",
    "        marker=dict(size=3, color=\"lightgray\"),\n",
    "        customdata=np.arange(len(xy)),\n",
    "        hovertemplate=\"node %{customdata}<extra></extra>\",\n",
    "        showlegend=False,\n",
    "    ))\n",
    "    fig.update_layout(\n",
    "        paper_bgcolor=\"white\", plot_bgcolor=\"white\",\n",
    "        margin=dict(l=0, r=0, t=30, b=0),\n",
    "        xaxis=dict(visible=False),\n",
    "        yaxis=dict(visible=False, scaleanchor=\"x\", scaleratio=1),\n",
    "    )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extract-layout",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract 2D camera layout for plotting\n",
    "# Try COLMAP output first, then fall back to poses.pkl\n",
    "\n",
    "xy = None\n",
    "\n",
    "# Option A: Read from COLMAP images.txt in the reconstruction output\n",
    "colmap_dirs = [\n",
    "    OUTPUT_ROOT / \"results\" / \"ba_output\",\n",
    "    OUTPUT_ROOT / \"results\" / \"vggt\",\n",
    "    OUTPUT_ROOT / \"results\" / \"merged\",\n",
    "]\n",
    "for d in colmap_dirs:\n",
    "    images_txt = d / \"images.txt\"\n",
    "    if images_txt.exists():\n",
    "        try:\n",
    "            from gtsfm.utils.io import read_images_txt\n",
    "            poses, _ = read_images_txt(str(images_txt))\n",
    "            xy = np.array([p.translation()[:2] for p in poses])\n",
    "            print(f\"Loaded {len(poses)} poses from {images_txt}\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to read {images_txt}: {e}\")\n",
    "\n",
    "# Option B: Saved poses pickle\n",
    "if xy is None:\n",
    "    poses_pkl = OUTPUT_ROOT / \"results\" / \"poses.pkl\"\n",
    "    if poses_pkl.exists():\n",
    "        from gtsfm.utils.io import load_poses\n",
    "        poses = load_poses(poses_pkl)\n",
    "        xy = np.array([p.translation()[:2] for p in poses])\n",
    "        print(f\"Loaded {len(poses)} poses from {poses_pkl}\")\n",
    "\n",
    "if xy is None:\n",
    "    print(\"WARNING: No camera poses found. Plotly graph visualizations will be skipped.\")\n",
    "    print(\"Expected COLMAP output in:\", [str(d) for d in colmap_dirs])\n",
    "else:\n",
    "    N = len(xy)\n",
    "    # Extract all edges from cluster tree\n",
    "    all_edges = list(cluster_tree.all_edges())\n",
    "    edges_arr = np.array(all_edges, dtype=int)\n",
    "    valid_mask = (edges_arr[:, 0] < N) & (edges_arr[:, 1] < N)\n",
    "    edges_arr = edges_arr[valid_mask]\n",
    "    print(f\"Total edges in cluster tree: {len(edges_arr)}, poses: {N}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad-edges-graph",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visibility graph with bad edges highlighted in red\n",
    "if xy is not None:\n",
    "    fig = create_base_figure_with_background(xy, edges_arr)\n",
    "\n",
    "    bad_edge_arr = np.array(\n",
    "        [e for e in bad_edges if e[0] < N and e[1] < N], dtype=int\n",
    "    )\n",
    "    if len(bad_edge_arr) > 0:\n",
    "        xe_bad, ye_bad = get_edge_coordinates(xy, bad_edge_arr)\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=xe_bad, y=ye_bad, mode=\"lines\",\n",
    "            line=dict(width=2, color=\"red\"),\n",
    "            name=\"Bad edges\", hoverinfo=\"none\",\n",
    "        ))\n",
    "        bad_nodes = np.unique(bad_edge_arr.flatten())\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=xy[bad_nodes, 0], y=xy[bad_nodes, 1], mode=\"markers\",\n",
    "            marker=dict(size=8, color=\"red\", symbol=\"x\"),\n",
    "            name=\"Bad edge nodes\",\n",
    "            customdata=bad_nodes,\n",
    "            hovertemplate=\"node %{customdata}<extra></extra>\",\n",
    "        ))\n",
    "\n",
    "    fig.update_layout(title=\"Visibility Graph with Bad Edges (red)\")\n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"Skipped (no poses available)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leaf-clusters",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original METIS leaf cluster visualization\n",
    "if xy is not None:\n",
    "    leaves = list(cluster_tree.leaves())\n",
    "    fig = create_base_figure_with_background(xy, edges_arr)\n",
    "\n",
    "    for idx, leaf in enumerate(leaves):\n",
    "        name = f\"Leaf {idx + 1}\"\n",
    "        nodes = np.array([k for k in leaf.all_keys() if 0 <= k < N], dtype=int)\n",
    "        if nodes.size == 0:\n",
    "            continue\n",
    "        mask = np.isin(edges_arr[:, 0], nodes) & np.isin(edges_arr[:, 1], nodes)\n",
    "        leaf_edges = edges_arr[mask]\n",
    "        xe, ye = get_edge_coordinates(xy, leaf_edges)\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=xe, y=ye, mode=\"lines\", line=dict(width=1),\n",
    "            hoverinfo=\"none\", name=name, legendgroup=name,\n",
    "        ))\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=xy[nodes, 0], y=xy[nodes, 1], mode=\"markers\",\n",
    "            marker=dict(size=6), name=name, legendgroup=name,\n",
    "            showlegend=False, customdata=nodes,\n",
    "            hovertemplate=\"node %{customdata}<extra></extra>\",\n",
    "        ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=\"Original METIS Leaf Clusters\",\n",
    "        legend=dict(groupclick=\"togglegroup\"),\n",
    "    )\n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"Skipped (no poses available)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "per-cluster-header",
   "metadata": {},
   "source": [
    "## 4. Bad Edges Per Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "per-cluster-bar",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaves = list(cluster_tree.leaves())\n",
    "\n",
    "labels = []\n",
    "total_counts = []\n",
    "bad_counts = []\n",
    "\n",
    "for idx, leaf in enumerate(leaves):\n",
    "    leaf_edges = set(leaf.value)\n",
    "    n_bad = len(leaf_edges & bad_edges)\n",
    "    labels.append(f\"Leaf {idx + 1}\")\n",
    "    total_counts.append(len(leaf_edges))\n",
    "    bad_counts.append(n_bad)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(max(8, len(labels) * 0.8), 5))\n",
    "x = np.arange(len(labels))\n",
    "width = 0.35\n",
    "ax.bar(x - width / 2, total_counts, width, label=\"Total edges\", color=\"steelblue\", alpha=0.7)\n",
    "ax.bar(x + width / 2, bad_counts, width, label=\"Bad edges\", color=\"red\", alpha=0.7)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels, rotation=45, ha=\"right\")\n",
    "ax.set_ylabel(\"Edge count\")\n",
    "ax.set_title(\"Bad Edges per Leaf Cluster\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print details\n",
    "for lbl, tot, bad in zip(labels, total_counts, bad_counts):\n",
    "    pct = 100.0 * bad / tot if tot > 0 else 0\n",
    "    print(f\"  {lbl}: {bad}/{tot} bad ({pct:.0f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prune-header",
   "metadata": {},
   "source": [
    "## 5. Re-partition After Pruning Bad Edges\n",
    "Remove bad edges from the visibility graph and re-run METIS to see how the cluster tree changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prune-repartition",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtsfm.graph_partitioner.metis_partitioner import MetisPartitioner\n",
    "from gtsfm.products.visibility_graph import prune_edges\n",
    "\n",
    "original_graph = sorted(cluster_tree.all_edges())\n",
    "pruned_graph = prune_edges(original_graph, bad_edges)\n",
    "\n",
    "print(f\"Original: {len(original_graph)} edges\")\n",
    "print(f\"Pruned:   {len(pruned_graph)} edges (removed {len(original_graph) - len(pruned_graph)})\")\n",
    "print()\n",
    "\n",
    "partitioner = MetisPartitioner()\n",
    "pruned_cluster_tree = partitioner.run(pruned_graph)\n",
    "\n",
    "orig_leaves = list(cluster_tree.leaves())\n",
    "pruned_leaves = list(pruned_cluster_tree.leaves()) if pruned_cluster_tree else []\n",
    "\n",
    "print(f\"Original: {len(orig_leaves)} leaf clusters\")\n",
    "print(f\"Pruned:   {len(pruned_leaves)} leaf clusters\")\n",
    "print()\n",
    "print(\"=== ORIGINAL ===\")\n",
    "print(cluster_tree)\n",
    "print()\n",
    "print(\"=== PRUNED ===\")\n",
    "print(pruned_cluster_tree if pruned_cluster_tree else \"(empty -- graph may be disconnected)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pruned-viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pruned cluster visualization\n",
    "if xy is not None and pruned_cluster_tree is not None:\n",
    "    pruned_edges_arr = np.array(pruned_graph, dtype=int)\n",
    "    valid_mask = (pruned_edges_arr[:, 0] < N) & (pruned_edges_arr[:, 1] < N)\n",
    "    pruned_edges_arr = pruned_edges_arr[valid_mask]\n",
    "\n",
    "    fig = create_base_figure_with_background(xy, pruned_edges_arr)\n",
    "\n",
    "    for idx, leaf in enumerate(pruned_cluster_tree.leaves()):\n",
    "        name = f\"Leaf {idx + 1}\"\n",
    "        nodes = np.array([k for k in leaf.all_keys() if 0 <= k < N], dtype=int)\n",
    "        if nodes.size == 0:\n",
    "            continue\n",
    "        mask = np.isin(pruned_edges_arr[:, 0], nodes) & np.isin(pruned_edges_arr[:, 1], nodes)\n",
    "        leaf_edges = pruned_edges_arr[mask]\n",
    "        xe, ye = get_edge_coordinates(xy, leaf_edges)\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=xe, y=ye, mode=\"lines\", line=dict(width=1),\n",
    "            hoverinfo=\"none\", name=name, legendgroup=name,\n",
    "        ))\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=xy[nodes, 0], y=xy[nodes, 1], mode=\"markers\",\n",
    "            marker=dict(size=6), name=name, legendgroup=name,\n",
    "            showlegend=False, customdata=nodes,\n",
    "            hovertemplate=\"node %{customdata}<extra></extra>\",\n",
    "        ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=\"Pruned Visibility Graph - Leaf Clusters\",\n",
    "        legend=dict(groupclick=\"togglegroup\"),\n",
    "    )\n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"Skipped (no poses or empty pruned tree)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "waeioj05tr",
   "source": "## 6. Original vs Pruned Pipeline Comparison\nCompare edge quality from the original run against the pruned run to measure the impact of removing bad edges.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "pe5c98cavh",
   "source": "# Load pruned run results\npruned_report = None\npruned_edge_quality = {}\npruned_bad_edges = set()\npruned_metadata = {}\n\nif PRUNED_EDGE_QUALITY_JSON.exists():\n    with open(PRUNED_EDGE_QUALITY_JSON) as f:\n        pruned_report = json.load(f)\n\n    for edge_str, stats in pruned_report[\"edge_quality\"].items():\n        i, j = map(int, edge_str.strip(\"()\").split(\",\"))\n        pruned_edge_quality[(i, j)] = stats\n\n    for s in pruned_report[\"bad_edges\"]:\n        i, j = map(int, s.strip(\"()\").split(\",\"))\n        pruned_bad_edges.add((i, j))\n\n    pruned_metadata = pruned_report[\"metadata\"]\n    print(f\"Pruned run — Total edges: {pruned_metadata['total_edges']}\")\n    print(f\"Pruned run — Bad edges:   {pruned_metadata['bad_edge_count']}\")\n    print(f\"Pruned run — Zero-track:  {pruned_metadata['edges_with_no_tracks']}\")\nelse:\n    print(f\"Pruned report not found at {PRUNED_EDGE_QUALITY_JSON}\")\n    print(\"Run the pipeline with --edge_quality_json to generate it.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "ysz5ptyo1x",
   "source": "# Side-by-side summary comparison\nif pruned_report is not None:\n    # Compute stats for original\n    orig_errors = [s[\"mean_reproj_error_px\"] for s in edge_quality.values() if s[\"mean_reproj_error_px\"] != \"inf\"]\n    pruned_errors = [s[\"mean_reproj_error_px\"] for s in pruned_edge_quality.values() if s[\"mean_reproj_error_px\"] != \"inf\"]\n\n    rows = [\n        (\"Total edges\", metadata[\"total_edges\"], pruned_metadata[\"total_edges\"]),\n        (\"Bad edges\", metadata[\"bad_edge_count\"], pruned_metadata[\"bad_edge_count\"]),\n        (\"Zero-track edges\", metadata[\"edges_with_no_tracks\"], pruned_metadata[\"edges_with_no_tracks\"]),\n        (\"Mean reproj error (px)\", f\"{np.mean(orig_errors):.2f}\", f\"{np.mean(pruned_errors):.2f}\" if pruned_errors else \"N/A\"),\n        (\"Median reproj error (px)\", f\"{np.median(orig_errors):.2f}\", f\"{np.median(pruned_errors):.2f}\" if pruned_errors else \"N/A\"),\n        (\"Max reproj error (px)\", f\"{np.max(orig_errors):.2f}\", f\"{np.max(pruned_errors):.2f}\" if pruned_errors else \"N/A\"),\n    ]\n\n    print(f\"{'Metric':<28} {'Original':>12} {'Pruned':>12} {'Delta':>12}\")\n    print(\"-\" * 66)\n    for label, orig, pruned in rows:\n        try:\n            delta = float(pruned) - float(orig)\n            delta_str = f\"{delta:+.2f}\" if isinstance(orig, str) else f\"{delta:+d}\"\n        except (ValueError, TypeError):\n            delta_str = \"\"\n        print(f\"{label:<28} {str(orig):>12} {str(pruned):>12} {delta_str:>12}\")\nelse:\n    print(\"Skipped (no pruned report)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "5or0vxknh1a",
   "source": "# Overlaid error distribution histograms\nif pruned_report is not None:\n    orig_errors = np.array([s[\"mean_reproj_error_px\"] for s in edge_quality.values() if s[\"mean_reproj_error_px\"] != \"inf\"])\n    pruned_errors = np.array([s[\"mean_reproj_error_px\"] for s in pruned_edge_quality.values() if s[\"mean_reproj_error_px\"] != \"inf\"])\n\n    fig, ax = plt.subplots(figsize=(10, 5))\n    bins = np.linspace(0, max(orig_errors.max(), pruned_errors.max() if len(pruned_errors) > 0 else 0) * 1.05, 50)\n    ax.hist(orig_errors, bins=bins, alpha=0.5, label=f\"Original ({len(orig_errors)} edges)\", color=\"steelblue\", edgecolor=\"black\")\n    ax.hist(pruned_errors, bins=bins, alpha=0.5, label=f\"Pruned ({len(pruned_errors)} edges)\", color=\"orange\", edgecolor=\"black\")\n    ax.axvline(5.0, color=\"red\", linestyle=\"--\", linewidth=1.5, label=\"Bad threshold (5px)\")\n    ax.set_xlabel(\"Mean Reprojection Error (px)\")\n    ax.set_ylabel(\"Count\")\n    ax.set_title(\"Error Distribution: Original vs Pruned\")\n    ax.legend()\n    plt.tight_layout()\n    plt.show()\nelse:\n    print(\"Skipped (no pruned report)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "iigqa3brjdg",
   "source": "# Per-edge error change scatter plot (edges present in both runs)\nif pruned_report is not None:\n    common_edges = set(edge_quality.keys()) & set(pruned_edge_quality.keys())\n    print(f\"Edges in both runs: {len(common_edges)}\")\n\n    orig_vals, pruned_vals, was_bad = [], [], []\n    for e in common_edges:\n        o = edge_quality[e][\"mean_reproj_error_px\"]\n        p = pruned_edge_quality[e][\"mean_reproj_error_px\"]\n        if o == \"inf\" or p == \"inf\":\n            continue\n        orig_vals.append(o)\n        pruned_vals.append(p)\n        was_bad.append(e in bad_edges)\n\n    orig_vals = np.array(orig_vals)\n    pruned_vals = np.array(pruned_vals)\n    was_bad = np.array(was_bad)\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n    ax.scatter(orig_vals[~was_bad], pruned_vals[~was_bad], alpha=0.4, s=15, c=\"steelblue\", label=\"Was good\")\n    ax.scatter(orig_vals[was_bad], pruned_vals[was_bad], alpha=0.6, s=25, c=\"red\", marker=\"x\", label=\"Was bad\")\n    lim = max(orig_vals.max(), pruned_vals.max()) * 1.05\n    ax.plot([0, lim], [0, lim], \"k--\", linewidth=0.8, alpha=0.5, label=\"No change (y=x)\")\n    ax.set_xlabel(\"Original reproj error (px)\")\n    ax.set_ylabel(\"Pruned reproj error (px)\")\n    ax.set_title(\"Per-Edge Error: Original vs Pruned\")\n    ax.legend()\n    ax.set_aspect(\"equal\")\n    plt.tight_layout()\n    plt.show()\n\n    improved = np.sum(pruned_vals < orig_vals - 0.5)\n    worsened = np.sum(pruned_vals > orig_vals + 0.5)\n    similar = len(orig_vals) - improved - worsened\n    print(f\"Improved (> 0.5px better): {improved}\")\n    print(f\"Worsened (> 0.5px worse):  {worsened}\")\n    print(f\"Similar (within 0.5px):    {similar}\")\nelse:\n    print(\"Skipped (no pruned report)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "v5uh0xgi76s",
   "source": "# Bad edge set comparison: fixed, persistent, new\nif pruned_report is not None:\n    # Edges in both runs\n    common_edges = set(edge_quality.keys()) & set(pruned_edge_quality.keys())\n\n    fixed = bad_edges - pruned_bad_edges  # were bad, now good (or removed entirely)\n    persistent = bad_edges & pruned_bad_edges  # bad in both\n    new_bad = pruned_bad_edges - bad_edges  # were good, now bad\n\n    print(f\"Fixed (bad -> good):       {len(fixed)}\")\n    print(f\"Persistent (bad -> bad):   {len(persistent)}\")\n    print(f\"New bad (good -> bad):     {len(new_bad)}\")\n    print()\n\n    if new_bad:\n        print(\"NEW bad edges (regressions from pruning):\")\n        for e in sorted(new_bad):\n            stats = pruned_edge_quality.get(e, {})\n            err = stats.get(\"mean_reproj_error_px\", \"?\")\n            tracks = stats.get(\"num_tracks\", \"?\")\n            err_str = f\"{err:.1f}\" if isinstance(err, (int, float)) else err\n            print(f\"  ({e[0]},{e[1]}): err={err_str}px, tracks={tracks}\")\n    else:\n        print(\"No new bad edges introduced by pruning.\")\nelse:\n    print(\"Skipped (no pruned report)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "4oyp59ms78a",
   "source": "# Per-cluster bad edge comparison for the pruned run\nif pruned_report is not None and PRUNED_CLUSTER_TREE_PKL.exists():\n    with open(PRUNED_CLUSTER_TREE_PKL, \"rb\") as f:\n        pruned_cluster_tree_loaded = pickle.load(f)\n\n    pruned_leaves = list(pruned_cluster_tree_loaded.leaves())\n\n    labels = []\n    total_counts = []\n    bad_counts = []\n    for idx, leaf in enumerate(pruned_leaves):\n        leaf_edges = set(leaf.value)\n        n_bad = len(leaf_edges & pruned_bad_edges)\n        labels.append(f\"Leaf {idx + 1}\")\n        total_counts.append(len(leaf_edges))\n        bad_counts.append(n_bad)\n\n    fig, ax = plt.subplots(figsize=(max(8, len(labels) * 0.8), 5))\n    x = np.arange(len(labels))\n    width = 0.35\n    ax.bar(x - width / 2, total_counts, width, label=\"Total edges\", color=\"steelblue\", alpha=0.7)\n    ax.bar(x + width / 2, bad_counts, width, label=\"Bad edges\", color=\"red\", alpha=0.7)\n    ax.set_xticks(x)\n    ax.set_xticklabels(labels, rotation=45, ha=\"right\")\n    ax.set_ylabel(\"Edge count\")\n    ax.set_title(\"Pruned Run: Bad Edges per Leaf Cluster\")\n    ax.legend()\n    plt.tight_layout()\n    plt.show()\n\n    for lbl, tot, bad in zip(labels, total_counts, bad_counts):\n        pct = 100.0 * bad / tot if tot > 0 else 0\n        print(f\"  {lbl}: {bad}/{tot} bad ({pct:.0f}%)\")\nelif pruned_report is not None:\n    print(f\"Pruned cluster tree not found at {PRUNED_CLUSTER_TREE_PKL}\")\nelse:\n    print(\"Skipped (no pruned report)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}