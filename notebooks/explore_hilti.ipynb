{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hilti explorer\n",
    "\n",
    "> Ayush Baid, Frank Dellaert\n",
    "\n",
    "A notebook to investigate the hilti dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import dask\n",
    "import plotly.express as px\n",
    "import gtsam\n",
    "from gtsam import Cal3Bundler, EssentialMatrix, Point3, Pose3, Rot3, Unit3\n",
    "from gtbook.drone import axes\n",
    "import hydra\n",
    "from dask.distributed import Client, LocalCluster\n",
    "from hydra.utils import instantiate\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "\n",
    "import gtsfm.utils.io as io_utils\n",
    "from gtsfm.loader.hilti_loader import HiltiLoader\n",
    "from gtsfm.common.gtsfm_data import GtsfmData\n",
    "from gtsfm.common.image import Image\n",
    "from gtsfm.common.keypoints import Keypoints\n",
    "from gtsfm.frontend.detector_descriptor.sift import SIFTDetectorDescriptor\n",
    "from gtsfm.frontend.matcher.twoway_matcher import TwoWayMatcher\n",
    "from gtsfm.utils import viz\n",
    "from gtsfm.frontend.verifier.ransac import Ransac\n",
    "from gtsfm.scene_optimizer import SceneOptimizer\n",
    "from gtsfm.retriever.sequential_hilti_retriever import SequentialHiltiRetriever\n",
    "from gtsfm.two_view_estimator import TwoViewEstimator\n",
    "import gtsfm.utils.geometry_comparisons as comp_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = Path.cwd()\n",
    "folder_path = Path(cwd.parent / \"tests\" / \"data\" / \"hilti_exp4_medium\")\n",
    "print(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls /Users/dellaert/git/gtsfm/tests/data/hilti_exp4_medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Images\n",
    "indices = range(300, 300+20)\n",
    "loader = HiltiLoader(base_folder=str(folder_path))\n",
    "images = [loader.get_image(i) for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translations = np.array([loader.get_absolute_pose_prior(i).value.translation() for i in range(len(loader))])\n",
    "print(translations.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wTimu0 = Pose3(Rot3(Point3(1, 0, 0), Point3(0, -1, 0), Point3(0, 0, -1)), Point3(0, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rig_indices = range(0, 250)\n",
    "wTimu = {i: (wTimu0 * loader._w_T_imu[i]) for i in rig_indices}\n",
    "translations = np.array([t.translation() for t in wTimu.values()])\n",
    "\n",
    "# print(poses)\n",
    "fig = px.scatter_3d(x=translations[:, 0], y=translations[:, 1], z=translations[:, 2])\n",
    "for t in wTimu.values():\n",
    "    fig.add_traces(axes(t))\n",
    "\n",
    "fig.add_traces(axes(Pose3()))\n",
    "\n",
    "# camera = dict(\n",
    "#     up=dict(x=0, y=0, z=-1),\n",
    "#     # center=dict(x=0, y=0, z=0),\n",
    "#     # eye=dict(x=1.25, y=1.25, z=1.25)\n",
    "# )\n",
    "\n",
    "fig.update_traces(marker=dict(size=3))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with hydra.initialize_config_module(config_module=\"gtsfm.configs\"):\n",
    "    # config is relative to the gtsfm module\n",
    "    cfg = hydra.compose(\n",
    "        config_name=\"deep_front_end\",\n",
    "    )\n",
    "    # print(cfg)\n",
    "    scene_optimizer: SceneOptimizer = instantiate(cfg.SceneOptimizer)\n",
    "\n",
    "retriever = SequentialHiltiRetriever(max_frame_lookahead=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rig_indices_filter = range(60, 65)\n",
    "image_indices_filter = range(300, 300 + 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dask client\n",
    "cluster = LocalCluster(\n",
    "    n_workers=1, threads_per_worker=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_graph = retriever.create_computation_graph(loader)\n",
    "with Client(cluster):\n",
    "    image_pair_indices = pairs_graph.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_pair_indices = [(i1, i2) for (i1, i2) in image_pair_indices if i1 in image_indices_filter and i2 in image_indices_filter]\n",
    "print(subset_pair_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i2Ri1_graph, i2Ui1_graph = scene_optimizer.create_computation_graph_for_frontend(\n",
    "    image_pair_indices=subset_pair_indices, \n",
    "    image_graph=loader.create_computation_graph_for_images(),\n",
    "    all_intrinsics=loader.create_computation_graph_for_intrinsics(),\n",
    "    image_shapes = loader.create_computation_graph_for_image_shapes(),\n",
    "    relative_pose_priors = loader.get_relative_pose_priors(subset_pair_indices),\n",
    "    gt_poses_graph = loader.create_computation_graph_for_poses())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_input = dask.delayed([i2Ri1_graph, i2Ui1_graph])\n",
    "with Client(cluster):\n",
    "    i2Ri1_dict, i2Ui1_dict = dask_input.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_relative_rotation(i1, i2):\n",
    "    i2Ri1_sample = i2Ri1_dict[(i1, i2)]\n",
    "    print(\"recovered i1Ri2 matrix\")\n",
    "    print(np.round(i2Ri1_sample.inverse().matrix(), 2))\n",
    "    print(\"recovered i1Ri2 xyz\")\n",
    "    print(np.round(np.degrees(i2Ri1_sample.inverse().xyz()), 2))\n",
    "\n",
    "    print(\"prior i1Ri2\")\n",
    "    print(np.round(loader.get_relative_pose_prior(i1, i2).value.inverse().rotation().matrix(), 2))\n",
    "    print(np.round(np.degrees(loader.get_relative_pose_prior(i1, i2).value.inverse().rotation().xyz()), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm the rotation from front-right (300) to right (303)\n",
    "debug_relative_rotation(300, 303)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm the rotation from front-left (301) to front-left (306)\n",
    "debug_relative_rotation(301, 306)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm the rotation from front-right (300) to front-right (305)\n",
    "debug_relative_rotation(300, 305)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate 2-view relative rotations\n",
    "for (i1, i2), i2Ri1 in i2Ri1_dict.items():\n",
    "    i2Ri1_prior = loader.get_relative_pose_prior(i1, i2).value.rotation()\n",
    "\n",
    "    R_angular_error = comp_utils.compute_relative_rotation_angle(i2Ri1, i2Ri1_prior)\n",
    "    if R_angular_error is not None and R_angular_error < 1:\n",
    "        print(i1, i2, R_angular_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i2Ri1_input_hacked = dict(i2Ri1_dict)\n",
    "\n",
    "hacked_pairs = [(300, 302), (305, 307), (310, 312), (315, 317)]\n",
    "for (i1, i2) in hacked_pairs:\n",
    "    i2Ri1_from_prior = loader.get_relative_pose_prior(i1, i2).value.rotation()\n",
    "    i2Ri1_input_hacked[(i1, i2)] = i2Ri1_from_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import gtsfm.averaging.rotation.shonan as shonan_\n",
    "importlib.reload(shonan_)\n",
    "shonan = shonan_.ShonanRotationAveraging()\n",
    "wRi_shonan = shonan.run(320, i2Ri1_dict=i2Ri1_input_hacked, i2Ti1_priors=[])[300:320]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, wRi in enumerate(wRi_shonan):\n",
    "    print(300 + i, np.round(wRi.matrix(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate 2-view relative rotations\n",
    "for (i1, i2), i2Ri1 in i2Ri1_dict.items():\n",
    "    i2Ri1_prior = loader.get_relative_pose_prior(i1, i2).value.rotation()\n",
    "\n",
    "    R_angular_error_2view = comp_utils.compute_relative_rotation_angle(i2Ri1, i2Ri1_prior)\n",
    "    if R_angular_error_2view is None: continue\n",
    "\n",
    "    i2Ri1_shonan = wRi_shonan[i2-300].between(wRi_shonan[i1-300])\n",
    "\n",
    "    R_angular_error_shonan = np.round(comp_utils.compute_relative_rotation_angle(i2Ri1_shonan, i2Ri1_prior), 2)\n",
    "\n",
    "    print(i1, i2, np.round(R_angular_error_2view, 2), R_angular_error_shonan, np.round((-R_angular_error_2view+R_angular_error_shonan), 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wRi_gt = [loader.get_camera_pose(i).rotation() for i in range(300, 320)]\n",
    "\n",
    "print(len(wRi_shonan))\n",
    "print(len(wRi_gt))\n",
    "\n",
    "wRi_shonan_aligned = comp_utils.align_rotations(wRi_gt, wRi_shonan)\n",
    "error = [\n",
    "    comp_utils.compute_relative_rotation_angle(aRi, aRi_)\n",
    "    for (aRi, aRi_) in zip(wRi_shonan_aligned, wRi_gt)\n",
    "]\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect features\n",
    "detector_descriptor = SIFTDetectorDescriptor()\n",
    "features = [detector_descriptor.detect_and_describe(image) for image in images]\n",
    "for i,(f,d) in enumerate(features):\n",
    "    print(f\"image {i+1}: {d.shape[0]} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do matching\n",
    "matcher = TwoWayMatcher(ratio_test_threshold=0.8)\n",
    "keypoints_i1, descriptors_i1 = features[0]\n",
    "keypoints_i2, descriptors_i2 = features[1]\n",
    "image_shape_i1 = images[0].value_array.shape\n",
    "image_shape_i2 = images[1].value_array.shape\n",
    "match_indices = matcher.match(\n",
    "    keypoints_i1, keypoints_i2, descriptors_i1, descriptors_i2, image_shape_i1, image_shape_i2\n",
    ")\n",
    "print(f\"{match_indices.shape[0]} matched.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get intrinsics\n",
    "camera_intrinsics_i1, camera_intrinsics_i2, *others = [loader.get_camera_intrinsics_full_res(i) for i in indices]\n",
    "print(camera_intrinsics_i1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do verification\n",
    "verifier = Ransac(use_intrinsics_in_verification=False,\n",
    "                  estimation_threshold_px=2)\n",
    "i2Ri1, i2Ui1, v_corr_idxs, inlier_ratio_est_model = verifier.verify(\n",
    "    keypoints_i1, keypoints_i2, match_indices, camera_intrinsics_i1, camera_intrinsics_i2)\n",
    "print(f\"ypr={np.degrees(i2Ri1.xyz())}\\nU={i2Ui1.point3().T}\\nverified:{v_corr_idxs.shape}\\n{inlier_ratio_est_model=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correspondence_image = viz.plot_twoview_correspondences(*images[:2], keypoints_i1, keypoints_i2, v_corr_idxs)\n",
    "fig = plt.figure(figsize=(12, 18), dpi=80)\n",
    "fig.gca().imshow(correspondence_image.value_array)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create estimator\n",
    "two_view_estimator = TwoViewEstimator(\n",
    "    matcher=None, verifier=None, inlier_support_processor=None,\n",
    "    bundle_adjust_2view=True, eval_threshold_px=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i2Ri1_optimized, i2Ui1_optimized, corr_idxs = two_view_estimator.bundle_adjust(\n",
    "    keypoints_i1, keypoints_i2, v_corr_idxs, camera_intrinsics_i1, camera_intrinsics_i2, i2Ri1, i2Ui1)\n",
    "print(f\"ypr={np.degrees(i2Ri1_optimized.xyz())}\\nU={i2Ui1_optimized.point3().T}\\nverified:{corr_idxs.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correspondence_image = viz.plot_twoview_correspondences(*images, keypoints_i1, keypoints_i2, corr_idxs)\n",
    "fig = plt.figure(figsize=(12, 18), dpi=80)\n",
    "fig.gca().imshow(correspondence_image.value_array)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4fd427e5d3afc8e77fd80f60207859a2afe2c687da56f6de3914baf61d886f83"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('gtsfm-v1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
